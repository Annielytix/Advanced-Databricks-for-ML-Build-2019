{"cells":[{"cell_type":"markdown","source":["## Text Analysis\nIn this lab, you will create a classification model that performs sentiment analysis of tweets.\n### Import Spark SQL and Spark ML Libraries\n\nFirst, import the libraries you will need:"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover"],"metadata":{"scrolled":false,"collapsed":false},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["### Load Source Data\nNow load the tweets data into a DataFrame. This data consists of tweets that have been previously captured and classified as positive or negative."],"metadata":{}},{"cell_type":"code","source":["tweets_csv = spark.read.csv('wasb://spark@<YOUR_ACCOUNT>.blob.core.windows.net/data/tweets.csv', inferSchema=True, header=True)\ntweets_csv.show(truncate = False)"],"metadata":{"scrolled":false,"collapsed":false},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["### Prepare the Data\nThe features for the classification model will be derived from the tweet text. The label is the sentiment (1 for positive, 0 for negative)"],"metadata":{}},{"cell_type":"code","source":["data = tweets_csv.select(\"SentimentText\", col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\ndata.show(truncate = False)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["### Split the Data\nIn common with most classification modeling processes, you'll split the data into a set for training, and a set for testing the trained model."],"metadata":{}},{"cell_type":"code","source":["splits = data.randomSplit([0.7, 0.3])\ntrain = splits[0]\ntest = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\ntrain_rows = train.count()\ntest_rows = test.count()\nprint (\"Training Rows:\", train_rows, \" Testing Rows:\", test_rows)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["### Define the Pipeline\nThe pipeline for the model consist of the following stages:\n- A Tokenizer to split the tweets into individual words.\n- A StopWordsRemover to remove common words such as \"a\" or \"the\" that have little predictive value.\n- A HashingTF class to generate numeric vectors from the text values.\n- A LogisticRegression algorithm to train a binary classification model."],"metadata":{}},{"cell_type":"code","source":["tokenizer = Tokenizer(inputCol=\"SentimentText\", outputCol=\"SentimentWords\")\nswr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"MeaningfulWords\")\nhashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10, regParam=0.01)\npipeline = Pipeline(stages=[tokenizer, swr, hashTF, lr])"],"metadata":{"scrolled":false,"collapsed":false},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["### Run the Pipeline as an Estimator\nThe pipeline itself is an estimator, and so it has a **fit** method that you can call to run the pipeline on a specified DataFrame. In this case, you will run the pipeline on the training data to train a model."],"metadata":{}},{"cell_type":"code","source":["piplineModel = pipeline.fit(train)\nprint (\"Pipeline complete!\")"],"metadata":{"scrolled":false,"collapsed":false},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["### Test the Pipeline Model\nThe model produced by the pipeline is a transformer that will apply all of the stages in the pipeline to a specified DataFrame and apply the trained model to generate predictions. In this case, you will transform the **test** DataFrame using the pipeline to generate label predictions."],"metadata":{}},{"cell_type":"code","source":["prediction = piplineModel.transform(test)\npredicted = prediction.select(\"SentimentText\", \"prediction\", \"trueLabel\")\npredicted.show(100, truncate = False)"],"metadata":{"scrolled":false,"collapsed":false},"outputs":[],"execution_count":14}],"metadata":{"kernelspec":{"display_name":"PySpark","name":"pysparkkernel","language":""},"language_info":{"mimetype":"text/x-python","pygments_lexer":"python2","name":"pyspark","codemirror_mode":{"version":2,"name":"python"}},"name":"Python Text Analysis","notebookId":3378903555804445},"nbformat":4,"nbformat_minor":0}
